{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data_process",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yingchengsun/Opinion-Spam-Detection/blob/master/Data_process.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLIyqeyhguO2",
        "colab_type": "code",
        "outputId": "919dc31b-9612-4001-ece3-9c7f559bbdba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aS4SKFQCKS13",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "from collections import OrderedDict\n",
        "import urllib\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import binascii\n",
        "import pickle\n",
        "import base64\n",
        "import re\n",
        "import sys\n",
        "import os.path\n",
        "import time\n",
        "\n",
        "yelp=\"https://www.yelp.com\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQQBLwa5KYqo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "transfer the original URL to 16 bit based coding address\n",
        "'''\n",
        "def transURL(s):\n",
        "    #s=\"a b c\"\n",
        "    trans=''\n",
        "    for x in s:\n",
        "        code = ord(x)\n",
        "        if (code>64 and code<91) or (code>96 and code<123) or (code>47 and code<58):\n",
        "            trans += x\n",
        "        else:\n",
        "            #trans += \"%\" + x.encode(\"hex\") #python 2.7\n",
        "            x = x.encode('utf-8') #python 3\n",
        "            trans += \"%\" + bytes.decode(base64.b16encode(x)) #python 3\n",
        "    return trans"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGj9pe-tuBmQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def download_images(reviewBody):\n",
        "    pre_images=reviewBody.findAll('div',{\"class\":\"photo-box photo-box--interactive is-loading\"})\n",
        "    for pre_image in pre_images:\n",
        "        image = pre_image.find('img')\n",
        "        image_url = image['data-async-src']\n",
        "        image_name = image_url.split('/')[-2]\n",
        "        urllib.urlretrieve(image_url,'pictures/'+'%s.jpg' % image_name)\n",
        "\n",
        "        more =  reviewBody.find('li',{\"class\":\"more-review-photos\"})\n",
        "        if more:\n",
        "            print more.find('a')['href']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cM1UvmBYhtV9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extractReviews(url, num_of_reviews, biz_id):\n",
        "\n",
        "    write_file_name = biz_id + \".json\"\n",
        "    with open(\"/content/drive/My Drive/Yelp/not_scraped.txt\", \"w+\") as not_scraped:\n",
        "      with open(\"/content/drive/My Drive/Yelp/Data/\" + write_file_name, \"w\") as write_file:\n",
        "        start = 0\n",
        "        num_of_items_perpage = 20\n",
        "        end = num_of_reviews\n",
        "        while (start < end):\n",
        "            url_ = url + '?start=' + str(start) + '&start='+ str(start)\n",
        "            start += num_of_items_perpage\n",
        "            #print (url_)\n",
        "            page = urllib.request.urlopen(url_)\n",
        "            soup = BeautifulSoup(page)\n",
        "            \n",
        "            r= soup.find(\"script\",{\"type\":\"application/json\",\"data-hypernova-key\":\"yelp_main__c0b64b766510882c5f527d24ec7f3ed5d144aa37__yelp_main__BizDetailsApp__dynamic\"})\n",
        "            \n",
        "            n_r = soup.find(\"a\", string=re.compile(\"not currently recommended\"))\n",
        "                                                                                  \n",
        "            \n",
        "            if not r:\n",
        "              reviews  = soup.findAll('div', class_ = 'review review--with-sidebar')\n",
        "              for item in reviews:\n",
        "                new_features_and_label = {}\n",
        "                new_features_and_label['review_id'] = item['data-review-id']\n",
        "                has_photo = item.find('ul', class_ = \"photo-box-grid clearfix js-content-expandable lightbox-media-parent\")\n",
        "                if has_photo == None:\n",
        "                  new_features_and_label['totalPhotos'] = 0\n",
        "                else:\n",
        "                  new_features_and_label['totalPhotos'] = len(has_photo.findAll('li'))\n",
        "                \n",
        "                reply = item.find('div', class_ = 'island biz-owner-reply clearfix')   \n",
        "                if reply:\n",
        "                  new_features_and_label['voterText'] = reply.text.lstrip().rstrip().split('\\n')[-1].lstrip()\n",
        "                else:\n",
        "                  new_features_and_label['voterText'] = None\n",
        "                new_features_and_label['label'] = 1\n",
        "                json.dump(new_features_and_label, write_file)\n",
        "                write_file.write('\\n')\n",
        "            else:\n",
        "              r_json = (r.text.lstrip('<!--').rstrip('-->'))\n",
        "              data_item = json.loads(r_json, object_pairs_hook=OrderedDict)\n",
        "              reviews = data_item['bizDetailsPageProps']['reviewFeedQueryProps']['reviews']\n",
        "              for item in reviews:\n",
        "                new_features_and_label = {}\n",
        "                new_features_and_label['review_id'] = item['id']\n",
        "                new_features_and_label['totalPhotos'] = item['totalPhotos']\n",
        "                new_features_and_label['voterText'] = item['feedback']['voterText']\n",
        "                new_features_and_label['label'] = 1\n",
        "                json.dump(new_features_and_label, write_file)\n",
        "                write_file.write('\\n')\n",
        "               \n",
        "        n_r_URL = yelp + n_r['href']\n",
        "        n_r_Number = n_r.text.split()[0]\n",
        "        print (n_r_Number)\n",
        "        \n",
        "        start = 0\n",
        "        num_of_items_perpage = 10\n",
        "        end = int(n_r_Number)\n",
        "        while (start < end):\n",
        "            url_ = n_r_URL + '?not_recommended_start=' + str(start)\n",
        "            print (url_)\n",
        "            page = urllib.request.urlopen(url_)\n",
        "            soup = BeautifulSoup(page)\n",
        "\n",
        "            for item in soup.findAll('div',{\"class\":\"review review--with-sidebar\"}):\n",
        "                new_features_and_label = {}\n",
        "                new_features_and_label['review_id'] = item['data-review-id']\n",
        "                \n",
        "                photos = item.find(\"li\", class_=\"photo-count responsive-small-display-inline-block\")\n",
        "                if photos != None:\n",
        "                  new_features_and_label['totalPhotos'] = int(photos.b.text)\n",
        "                else:\n",
        "                  new_features_and_label['totalPhotos'] = 0\n",
        "                \n",
        "                new_features_and_label['user_id'] = item.find('span', class_ = \"user-display-name\")['data-hovercard-id']\n",
        "                new_features_and_label['reviews'] = item.find('div', class_=\"review-content\").p.text\n",
        "                if start > 0 and new_features_and_label['reviews'] == \"This review has been removed for violating our Terms of Service\":\n",
        "                  continue\n",
        "                new_features_and_label['label'] = 0\n",
        "               \n",
        "                json.dump(new_features_and_label, write_file)\n",
        "                write_file.write('\\n')\n",
        "            start += num_of_items_perpage\n",
        "    \n",
        "   \n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzXd4iKg0m4i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Collect \"recommendated\" and \"not recommended\" reviews by business ID \n",
        "#Main entrance\n",
        "'''\n",
        "\n",
        "with open('/content/drive/My Drive/Yelp/yelp_dataset/business.json', 'r') as biz_inf:\n",
        "  i= 0\n",
        "  for idx, line in enumerate(biz_inf):  \n",
        "      if idx >= 3:\n",
        "        break\n",
        "      print (idx, line)\n",
        "       \n",
        "      '''\n",
        "      read business from 'business.json'\n",
        "      '''\n",
        "      data_item = json.loads(line, object_pairs_hook=OrderedDict)\n",
        "      biz_name = data_item['name']\n",
        "      biz_id = data_item['business_id']\n",
        "\n",
        "      if os.path.exists('/content/drive/My Drive/Yelp/Data/' +biz_id+'.json'):\n",
        "        continue\n",
        "      time.sleep(3)\n",
        "      print (biz_name)\n",
        "      biz_postal = data_item['postal_code']\n",
        "      \n",
        "      '''\n",
        "      Search the business info and get the first one in the result list as the target\n",
        "      '''\n",
        "      search_url = yelp+\"/search?find_desc=\"+transURL(biz_name)+\"&find_loc=\"+transURL(biz_postal)\n",
        "      print (search_url)\n",
        "      search_result = urllib.request.urlopen(search_url)   \n",
        "      soup = BeautifulSoup(search_result)    \n",
        "      rankings = soup.findAll(\"p\",{\"class\":\"lemon--p__373c0__3Qnnj text__373c0__2pB8f text-color--black-regular__373c0__38bRH text-align--left__373c0__2pnx_ text-size--inherit__373c0__2gFQ3\"})\n",
        "      for item in rankings:\n",
        "        if item.text[0:2]==\"1.\": #the first one in the result list\n",
        "          biz_url = yelp + item.a['href']\n",
        "          num_of_reviews = item.findNext(\"span\",{\"class\":\"lemon--span__373c0__3997G text__373c0__2pB8f reviewCount__373c0__2r4xT text-color--mid__373c0__3G312 text-align--left__373c0__2pnx_\"}).text.split()[0]\n",
        "          num_of_reviews = int(num_of_reviews)\n",
        "          \n",
        "      #print (biz_url)\n",
        "      print (num_of_reviews)\n",
        "      \n",
        "      extractReviews(biz_url, num_of_reviews, biz_id)\n",
        "\n",
        "                    "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}